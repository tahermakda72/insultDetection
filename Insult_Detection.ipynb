{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wA7EVsErkqLa"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oG4133qNkqLe"
   },
   "outputs": [],
   "source": [
    "Classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel ='linear'),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=200),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-60I7tPkqLh"
   },
   "outputs": [],
   "source": [
    "data2=pd.read_csv(\"test_with_solutions.csv\")\n",
    "data1=pd.read_csv(\"train.csv\") #currently in use\n",
    "#data3=pd.read_csv(\"agr_en_train.csv\")\n",
    "#data4=pd.read_csv(\"agr_en_tw_gold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWhCD8CxkqLk"
   },
   "outputs": [],
   "source": [
    "data1.columns = ['Insult','Date','Comment']\n",
    "df1=pd.DataFrame([data1['Comment'],data1['Insult']]).T\n",
    "data2.columns = ['Insult','Date','Comment', 'Usage']\n",
    "df2=pd.DataFrame([data2['Comment'],data2['Insult']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6594, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames=[df1['Comment'],df2['Comment']]\n",
    "result=pd.DataFrame(pd.concat(frames))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQ7Rzl-vkqLp"
   },
   "outputs": [],
   "source": [
    "feature_extraction = TfidfVectorizer()\n",
    "data = feature_extraction.fit_transform(result[\"Comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data[0:3947,:]\n",
    "X_test=data[3947:,:]\n",
    "#df1['Insult']=df1['Insult'].astype(int)\n",
    "#df2['Insult']=df2['Insult'].astype(int)\n",
    "#y_train['Insult']=df1['Insult']\n",
    "#y_test['Insult']=df2['Insult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "count=0\n",
    "for a in df2['Insult']:\n",
    "    if a==1:\n",
    "        count=count+1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test['Insult']=df2['Insult']\n",
    "y_train=df1['Insult']\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_test=df2['Insult']\n",
    "y_test=pd.DataFrame(y_test)\n",
    "y_train.shape\n",
    "y_train=y_train.astype(int)\n",
    "y_test=y_test.astype(int)\n",
    "#df2['Insult']=df2['Insult'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2647, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2647, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976273186610954"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit = DecisionTreeClassifier().fit(X_train,y_train)\n",
    "pred = fit.predict(X_test)\n",
    "roc_auc_score(y_test, pred)\n",
    "#metrics.roc_curve(y_test, pred)\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test,pred,pos_label=2)\n",
    "# tpr.shape\n",
    "# auc = metrics.auc(fpr,tpr)\n",
    "# #print('Auc of '+classifier.__class__.__name__+'is '+str(auc))\n",
    "# auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1743
    },
    "colab_type": "code",
    "id": "MHNCpWIArViq",
    "outputId": "b1e8ca7a-067e-4bd0-c912-bdce6eb2cf4f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      1954\n",
      "           1       0.86      0.40      0.54       693\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      2647\n",
      "   macro avg       0.84      0.69      0.72      2647\n",
      "weighted avg       0.83      0.83      0.80      2647\n",
      "\n",
      "[[1909   45]\n",
      " [ 417  276]]\n",
      "Accuracy of LogisticRegressionis 0.8254627880619569\n",
      "Auc of LogisticRegressionis 0.6876193577831244\n",
      "=========================================================================\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "           weights='uniform') :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      1954\n",
      "           1       0.59      0.56      0.58       693\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2647\n",
      "   macro avg       0.72      0.71      0.72      2647\n",
      "weighted avg       0.78      0.79      0.78      2647\n",
      "\n",
      "[[1688  266]\n",
      " [ 303  390]]\n",
      "Accuracy of KNeighborsClassifieris 0.7850396675481678\n",
      "Auc of KNeighborsClassifieris 0.7133197747322619\n",
      "=========================================================================\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1954\n",
      "           1       0.81      0.52      0.63       693\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2647\n",
      "   macro avg       0.83      0.74      0.77      2647\n",
      "weighted avg       0.84      0.84      0.83      2647\n",
      "\n",
      "[[1872   82]\n",
      " [ 336  357]]\n",
      "Accuracy of SVCis 0.8420853796751039\n",
      "Auc of SVCis 0.7365931577804659\n",
      "=========================================================================\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1954\n",
      "           1       0.62      0.52      0.57       693\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2647\n",
      "   macro avg       0.73      0.70      0.71      2647\n",
      "weighted avg       0.78      0.79      0.79      2647\n",
      "\n",
      "[[1736  218]\n",
      " [ 333  360]]\n",
      "Accuracy of DecisionTreeClassifieris 0.791839818662637\n",
      "Auc of DecisionTreeClassifieris 0.7039572505283866\n",
      "=========================================================================\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88      1954\n",
      "           1       0.89      0.28      0.43       693\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      2647\n",
      "   macro avg       0.84      0.63      0.65      2647\n",
      "weighted avg       0.82      0.80      0.76      2647\n",
      "\n",
      "[[1931   23]\n",
      " [ 498  195]]\n",
      "Accuracy of RandomForestClassifieris 0.803173403853419\n",
      "Auc of RandomForestClassifieris 0.6348072773354247\n",
      "=========================================================================\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      1954\n",
      "           1       0.73      0.53      0.61       693\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2647\n",
      "   macro avg       0.79      0.73      0.75      2647\n",
      "weighted avg       0.82      0.82      0.81      2647\n",
      "\n",
      "[[1817  137]\n",
      " [ 327  366]]\n",
      "Accuracy of AdaBoostClassifieris 0.8247072157159048\n",
      "Auc of AdaBoostClassifieris 0.7290129692893256\n",
      "=========================================================================\n",
      "GaussianNB(priors=None, var_smoothing=1e-09) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      1954\n",
      "           1       0.42      0.50      0.45       693\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      2647\n",
      "   macro avg       0.61      0.63      0.62      2647\n",
      "weighted avg       0.71      0.69      0.70      2647\n",
      "\n",
      "[[1472  482]\n",
      " [ 347  346]]\n",
      "Accuracy of GaussianNBis 0.6868152625613902\n",
      "Auc of GaussianNBis 0.6263025045010715\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dense_features=X_train.toarray()\n",
    "dense_test= X_test.toarray()\n",
    "Accuracy=[]\n",
    "Model=[]\n",
    "Auc=[]\n",
    "for classifier in Classifiers:\n",
    "    print(\"=========================================================================\")\n",
    "    print(classifier,\":\")\n",
    "    try:\n",
    "        fit = classifier.fit(X_train,y_train)\n",
    "        pred = fit.predict(X_test)\n",
    "    except Exception:\n",
    "        fit = classifier.fit(dense_features,y_train)\n",
    "        pred = fit.predict(dense_test)\n",
    "    class_report = classification_report(y_test,pred)\n",
    "    print(class_report)\n",
    "    conf=confusion_matrix(y_test, pred)\n",
    "    print(conf)\n",
    "    accuracy = accuracy_score(pred,y_test)\n",
    "    Accuracy.append(accuracy)\n",
    "  #  fpr, tpr, thresholds = metrics.roc_curve(y_test,pred,pos_label=2)\n",
    "    auc = roc_auc_score(y_test, pred)\n",
    "    Auc.append(auc)\n",
    "    Model.append(classifier.__class__.__name__)\n",
    "    print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))\n",
    "    print('Auc of '+classifier.__class__.__name__+'is '+str(auc))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29    \"You really think shes speaking spanish? You a...\n",
      "Name: Comment, dtype: object\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "fit = SVC(kernel ='linear').fit(X_train,y_train)\n",
    "pred = fit.predict(X_test[29:30])\n",
    "print(df2['Comment'].iloc[29:30])\n",
    "print(pred)\n",
    "# a=df2['Comment'].iloc[29:30].astype(str)\n",
    "# print(a)\n",
    "# a=\"You really think shes speaking spanish? You a...\"\n",
    "# b=a.split(\" \")\n",
    "\n",
    "# for i in b:\n",
    "    \n",
    "#     s=fit.predict()\n",
    "#     print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gen_aggression_detection.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
